{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNl7i+ltWLyrtJFHamI5lGb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gmacario/learning-python/blob/master/jupyter/fcc-tutorial/fcc_opencv_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenCV Tutorial - Develop Computer Vision Apps in the Cloud with Python\n",
        "\n",
        "YouTube Video: <https://www.youtube.com/watch?v=iXNsAYOTzgM>"
      ],
      "metadata": {
        "id": "R_YrsiTBeARv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVoImdWIwzFh"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "! [ ! -d opencvTutorial ] && git clone https://github.com/misbah4064/opencvTutorial.git\n",
        "%cd opencvTutorial/\n",
        "! git pull\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: OpenCV Basics"
      ],
      "metadata": {
        "id": "4_GvmemTcpDx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lesson 1: Changing Image's Color Profiles"
      ],
      "metadata": {
        "id": "NJ7dq2hyciEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# dir(cv2_imshow)\n",
        "\n",
        "# Read image\n",
        "image = cv2.imread(\"images/color.jpg\")\n",
        "cv2_imshow(image)"
      ],
      "metadata": {
        "id": "7EcP0zLlcKUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the image properties\n",
        "\n",
        "print(image.shape)\n",
        "# --> (476 rows, 640 columns, 3 channels) --> Colorful image"
      ],
      "metadata": {
        "id": "nEvZAMX2dBzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the image grayscale\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
      ],
      "metadata": {
        "id": "1KH8AOMFeTed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(gray.shape)"
      ],
      "metadata": {
        "id": "pBmCxeHZfxn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(gray)"
      ],
      "metadata": {
        "id": "A5fHHdxcf-LN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HSV (Hue, Saturation, Variance) image --> All colors under one channel\n",
        "hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)"
      ],
      "metadata": {
        "id": "bjkewYNOgByf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hsv_image.shape\n",
        "cv2_imshow(hsv_image)"
      ],
      "metadata": {
        "id": "C5fM2K05i_IW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lesson 2: Edge Detection"
      ],
      "metadata": {
        "id": "3P_7R4tJkZNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv_imshow\n",
        "import numpy as np\n",
        "\n",
        "image = cv2.imread(\"images/color.jpg\")\n",
        "# cv2_imshow(image)\n",
        "\n",
        "# Canny Edge Detector - starts from a grayscale image\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "canny_image = cv2.Canny(gray, 150, 200)\n",
        "\n",
        "#cv2_imshow(canny_image)\n",
        "\n",
        "# Erosion and Dilation\n",
        "kernel = np.ones((5, 5), np.uint8)\n",
        "\n",
        "# First let's do ilation\n",
        "dilate_image = cv2.dilate(canny_image, kernel, iterations=1)\n",
        "# cv2_imshow(dilate_image)\n",
        "\n",
        "# Then Erosion\n",
        "erode_image = cv2.erode(dilate_image, kernel, iterations=1)\n",
        "# cv2_imshow(erode_image)\n",
        "\n",
        "display = np.hstack((canny_image, dilate_image, erode_image))\n",
        "cv2_imshow(display)\n"
      ],
      "metadata": {
        "id": "2XwLxkFyjCp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lesson 3: Image Manipulation and Noise Removal"
      ],
      "metadata": {
        "id": "0ZrZmevdqqql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "\n",
        "# Read image\n",
        "image_lion = cv2.imread(\"images/lion.jpg\")\n",
        "# cv2_imshow(image_lion)\n",
        "\n",
        "# Denoising\n",
        "# See https://docs.opencv.org/4.x/d5/d69/tutorial_py_non_local_means.html\n",
        "dst = cv2.fastNlMeansDenoisingColored(image_lion, None, 50, 20, 7, 15)\n",
        "\n",
        "# cv2_imshow(dst)\n",
        "\n",
        "display = np.hstack((image_lion, dst))\n",
        "# print(display.shape)\n",
        "cv2_imshow(display)"
      ],
      "metadata": {
        "id": "yFF1pivSkmpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lesson 4: Drawing Shapes and Writing Text on Images\n",
        "\n",
        "(Continue from 41:57 of video <https://www.youtube.com/watch?v=iXNsAYOTzgM>)"
      ],
      "metadata": {
        "id": "xZ8WAhK4x7PK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Create image from scratch\n",
        "img = np.zeros(shape=(512, 512, 3), dtype=np.uint8)\n",
        "#img.dtype\n",
        "#img.size\n",
        "\n",
        "# Drawing Function\n",
        "# Draw a green circle\n",
        "cv2.circle(img, (100,100), 50, (0,255,0), 5)\n",
        "# Draw a red rectangle\n",
        "cv2.rectangle(img, (200,200), (400,500), (0,0,255), 5)\n",
        "# Draw a blue line\n",
        "cv2.line(img, (160,160), (359,29), (255,0,0), 3)\n",
        "# Write a text\n",
        "cv2.putText(img, \"OpenCV\", (160,160), cv2.FONT_HERSHEY_COMPLEX, 2, (0,255,255), 2)\n",
        "# Display the image\n",
        "cv2_imshow(img)"
      ],
      "metadata": {
        "id": "NRBlPm3KIIx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Intermediate Exercises"
      ],
      "metadata": {
        "id": "lPShaE3ZbhvI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Lesson 1: Color Detection\n",
        "\n",
        "(Continue from 1:00:00 of video https://www.youtube.com/watch?v=iXNsAYOTzgM)"
      ],
      "metadata": {
        "id": "08TG-wkXbtte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Read the file into a BGR image (blue, green and red channels)\n",
        "img_shapes = cv2.imread(\"images/shapes.png\")\n",
        "# cv2_imshow(img_shapes)\n",
        "\n",
        "# Convert BGR to HSV\n",
        "hsv_image = cv2.cvtColor(img_shapes, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "# Red Color\n",
        "# lower_hue = np.array([0,0,0])\n",
        "# upper_hue = np.array([20,255,255])\n",
        "\n",
        "# Yellow Color\n",
        "lower_hue = np.array([21,0,0])\n",
        "upper_hue = np.array([45,255,255])\n",
        "\n",
        "# Green Color\n",
        "# lower_hue = np.array([46,0,0])\n",
        "# upper_hue = np.array([91,255,255])\n",
        "\n",
        "# Blue Color (Triangle)\n",
        "# lower_hue = np.array([65,0,0])\n",
        "# upper_hue = np.array([110,255,255])\n",
        "\n",
        "# You can search for \"OpenCV Trackbar\"\n",
        "\n",
        "mask = cv2.inRange(hsv_image, lower_hue, upper_hue)\n",
        "#cv2_imshow(mask)\n",
        "\n",
        "result = cv2.bitwise_and(img_shapes, img_shapes, mask=mask)\n",
        "cv2_imshow(result)"
      ],
      "metadata": {
        "id": "vQqbONC4I5AJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Lesson 2: Face Detection\n",
        "\n",
        "(Continue from 1:21:00 of video https://www.youtube.com/watch?v=iXNsAYOTzgM)"
      ],
      "metadata": {
        "id": "t2UL6GBVbHhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "# import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier(\"files/haarcascade_frontalface_default.xml\")\n",
        "print(f\"DEBUG: face_cascade={face_cascade}\")\n",
        "\n",
        "img = cv2.imread(\"images/person.jpg\")\n",
        "# img = cv2.imread(\"images/group.jpg\")\n",
        "\n",
        "# Convert BGR image to grayscale\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "print(f\"DEBUG: faces={faces}\")\n",
        "\n",
        "for (x,y,w,h) in faces:\n",
        "  cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 3)\n",
        "\n",
        "cv2_imshow(img)"
      ],
      "metadata": {
        "id": "cYRM-RhSIMbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lesson 3: Shape Detection\n",
        "\n",
        "(Continue from 1:38:00 of video https://www.youtube.com/watch?v=iXNsAYOTzgM)\n",
        "\n",
        "> Indented block\n",
        "\n"
      ],
      "metadata": {
        "id": "nV390NMrrW_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img = cv2.imread(\"images/shapes.png\")\n",
        "# print(img)\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "# cv2_imshow(gray)\n",
        "\n",
        "(ret, thresh) = cv2.threshold(gray, 50, 255, 1)\n",
        "cv2_imshow(thresh)\n",
        "contours, h = cv2.findContours(thresh, 1, 2)\n",
        "\n",
        "#print(contours)\n",
        "for cnt in contours:\n",
        "  approx = cv2.approxPolyDP(cnt, 0.01*cv2.arcLength(cnt, True), True)\n",
        "  print(len(approx))\n",
        "  n = len(approx)\n",
        "  if n == 3:\n",
        "    # This is a triangle\n",
        "    cv2.drawContours(img, [cnt], 0, (0,255,0), 3)    \n",
        "  elif n == 4:\n",
        "    # This is a square\n",
        "    cv2.drawContours(img, [cnt], 0, (255,0,255), 10)\n",
        "  elif n == 6:\n",
        "    # This is a hexagon\n",
        "    cv2.drawContours(img, [cnt], 0, (255,255,0), 5)    \n",
        "  elif n > 9:\n",
        "    # This is a circle\n",
        "    cv2.drawContours(img, [cnt], 0, (255,255,255), 15)\n",
        "\n",
        "\n",
        "#cv2.drawContours(gray, contours, 1, (0,255,0))\n",
        "cv2_imshow(img)"
      ],
      "metadata": {
        "id": "dquoz72ymf7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Projects"
      ],
      "metadata": {
        "id": "XTFzQfcg3SsK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Project 1: Tracking a Ball\n",
        "\n",
        "(Continue from 2:02:00 of video https://www.youtube.com/watch?v=iXNsAYOTzgM)\n",
        "\n",
        "How would you make a computer understand a ball is moving on the screen?\n",
        "\n"
      ],
      "metadata": {
        "id": "Ml1YHxPi1V0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "ball = []\n",
        "cap = cv2.VideoCapture(\"videos/video.mp4\")\n",
        "# print(cap)\n",
        "out = cv2.VideoWriter(\"output.avi\", cv2.VideoWriter_fourcc('M','J','P','G'), 10, (1920,1080))\n",
        "\n",
        "n_frame = 0\n",
        "while cap.isOpened():\n",
        "  ret, frame = cap.read()\n",
        "  if ret is False:\n",
        "    break\n",
        "  n_frame += 1\n",
        "  print(f\"DEBUG: Processing frame #{n_frame}\")\n",
        "  hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "  lower_hue = np.array([21,0,0])\n",
        "  upper_hue = np.array([42,255,255])\n",
        "  mask = cv2.inRange(hsv, lower_hue, upper_hue)\n",
        "\n",
        "  #cv2_imshow(mask)\n",
        "\n",
        "  # Find the ball using shape detection\n",
        "  #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "  #ret, thresh = cv2.threshold(gray, 50, 255, 1)\n",
        "  (contours, h) = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "  center = None\n",
        "\n",
        "  if len(contours) > 0:\n",
        "    # Find the contour in the sequence with the biggest area\n",
        "    c = max(contours, key=cv2.contourArea)\n",
        "    # Now locate this contour\n",
        "    ((x, y), radius) = cv2.minEnclosingCircle(c)\n",
        "    # print(f\"DEBUG: (x,y)={(x, y)}, radius={radius}\")\n",
        "    M = cv2.moments(c)\n",
        "    # print(f\"DEBUG: M={M}\")\n",
        "    try:\n",
        "      center = (int(M[\"m10\"]/M[\"m00\"]), int(M[\"m01\"]/M[\"m00\"]))\n",
        "      cv2.circle(frame, center, 10, (255,0,0), -1)\n",
        "      ball.append(center)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    if len(ball) > 2:\n",
        "      for i in range(1, len(ball)):\n",
        "        cv2.line(frame, ball[i-1], ball[i], (0,0,255), 5)\n",
        "\n",
        "    # DEBUG\n",
        "    # cv2_imshow(frame)\n",
        "\n",
        "  out.write(frame)\n",
        "out.release()\n",
        "\n",
        "print(f\"DEBUG: End of program\")"
      ],
      "metadata": {
        "id": "SWly9GhyrncU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Project 2: Face Recognition\n",
        "\n",
        "TODO\n",
        "\n",
        "(Continue from 2:29:00 of video https://www.youtube.com/watch?v=iXNsAYOTzgM)\n"
      ],
      "metadata": {
        "id": "bFRq9WChDEaT"
      }
    }
  ]
}
